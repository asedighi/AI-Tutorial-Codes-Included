{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install zarr numcodecs -q\n",
        "import zarr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numcodecs import Blosc, Delta, FixedScaleOffset\n",
        "import tempfile\n",
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(f\"Zarr version: {zarr.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "\n",
        "print(\"=== BASIC ZARR OPERATIONS ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1l8pfwNQZ6B",
        "outputId": "e9051598-7945-4366-c151-321a9d7b6950"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zarr version: 3.1.2\n",
            "NumPy version: 2.0.2\n",
            "=== BASIC ZARR OPERATIONS ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tutorial_dir = Path(tempfile.mkdtemp(prefix=\"zarr_tutorial_\"))\n",
        "print(f\"Working directory: {tutorial_dir}\")\n",
        "\n",
        "z1 = zarr.zeros((1000, 1000), chunks=(100, 100), dtype='f4',\n",
        "                store=str(tutorial_dir / 'basic_array.zarr'), zarr_format=2)\n",
        "z2 = zarr.ones((500, 500, 10), chunks=(100, 100, 5), dtype='i4',\n",
        "               store=str(tutorial_dir / 'multi_dim.zarr'), zarr_format=2)\n",
        "\n",
        "print(f\"2D Array shape: {z1.shape}, chunks: {z1.chunks}, dtype: {z1.dtype}\")\n",
        "print(f\"3D Array shape: {z2.shape}, chunks: {z2.chunks}, dtype: {z2.dtype}\")\n",
        "\n",
        "z1[100:200, 100:200] = np.random.random((100, 100)).astype('f4')\n",
        "z2[:, :, 0] = np.arange(500*500).reshape(500, 500)\n",
        "\n",
        "print(f\"Memory usage estimate: {z1.nbytes_stored() / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW_hhoB1QcVQ",
        "outputId": "607fcb44-9092-46d8-bc44-78f5c02c7682"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working directory: /tmp/zarr_tutorial_sx_lklbv\n",
            "2D Array shape: (1000, 1000), chunks: (100, 100), dtype: float32\n",
            "3D Array shape: (500, 500, 10), chunks: (100, 100, 5), dtype: int32\n",
            "Memory usage estimate: 0.03 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== ADVANCED CHUNKING ===\")\n",
        "\n",
        "time_steps, height, width = 365, 1000, 2000\n",
        "time_series = zarr.zeros(\n",
        "    (time_steps, height, width),\n",
        "    chunks=(30, 250, 500),\n",
        "    dtype='f4',\n",
        "    store=str(tutorial_dir / 'time_series.zarr'),\n",
        "    zarr_format=2\n",
        ")\n",
        "\n",
        "for t in range(0, time_steps, 30):\n",
        "    end_t = min(t + 30, time_steps)\n",
        "    seasonal = np.sin(2 * np.pi * np.arange(t, end_t) / 365)[:, None, None]\n",
        "    spatial = np.random.normal(20, 5, (end_t - t, height, width))\n",
        "    time_series[t:end_t] = (spatial + 10 * seasonal).astype('f4')\n",
        "\n",
        "print(f\"Time series created: {time_series.shape}\")\n",
        "print(f\"Approximate chunks created\")\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "temporal_slice = time_series[:, 500, 1000]\n",
        "temporal_time = time.time() - start\n",
        "\n",
        "start = time.time()\n",
        "spatial_slice = time_series[100, :200, :200]\n",
        "spatial_time = time.time() - start\n",
        "\n",
        "print(f\"Temporal access time: {temporal_time:.4f}s\")\n",
        "print(f\"Spatial access time: {spatial_time:.4f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByRYCPZBQjHH",
        "outputId": "c28f5578-b08e-41ec-9e04-621e5bee8c87"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ADVANCED CHUNKING ===\n",
            "Time series created: (365, 1000, 2000)\n",
            "Approximate chunks created\n",
            "Temporal access time: 0.2720s\n",
            "Spatial access time: 0.0223s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== COMPRESSION AND CODECS ===\")\n",
        "\n",
        "data = np.random.randint(0, 1000, (1000, 1000), dtype='i4')\n",
        "\n",
        "from zarr.codecs import BloscCodec, BytesCodec\n",
        "\n",
        "z_none = zarr.array(data, chunks=(100, 100),\n",
        "                   codecs=[BytesCodec()],\n",
        "                   store=str(tutorial_dir / 'no_compress.zarr'))\n",
        "\n",
        "z_lz4 = zarr.array(data, chunks=(100, 100),\n",
        "                   codecs=[BytesCodec(), BloscCodec(cname='lz4', clevel=5)],\n",
        "                   store=str(tutorial_dir / 'lz4_compress.zarr'))\n",
        "\n",
        "z_zstd = zarr.array(data, chunks=(100, 100),\n",
        "                    codecs=[BytesCodec(), BloscCodec(cname='zstd', clevel=9)],\n",
        "                    store=str(tutorial_dir / 'zstd_compress.zarr'))\n",
        "\n",
        "sequential_data = np.cumsum(np.random.randint(-5, 6, (1000, 1000)), axis=1)\n",
        "z_delta = zarr.array(sequential_data, chunks=(100, 100),\n",
        "                     codecs=[BytesCodec(), BloscCodec(cname='zstd', clevel=5)],\n",
        "                     store=str(tutorial_dir / 'sequential_compress.zarr'))\n",
        "\n",
        "sizes = {\n",
        "    'No compression': z_none.nbytes_stored(),\n",
        "    'LZ4': z_lz4.nbytes_stored(),\n",
        "    'ZSTD': z_zstd.nbytes_stored(),\n",
        "    'Sequential+ZSTD': z_delta.nbytes_stored()\n",
        "}\n",
        "\n",
        "print(\"Compression comparison:\")\n",
        "original_size = data.nbytes\n",
        "for name, size in sizes.items():\n",
        "    ratio = size / original_size\n",
        "    print(f\"{name}: {size/1024**2:.2f} MB (ratio: {ratio:.3f})\")\n",
        "\n",
        "print(\"\\n=== HIERARCHICAL DATA ORGANIZATION ===\")\n",
        "\n",
        "root = zarr.open_group(str(tutorial_dir / 'experiment.zarr'), mode='w')\n",
        "\n",
        "raw_data = root.create_group('raw_data')\n",
        "processed = root.create_group('processed')\n",
        "metadata = root.create_group('metadata')\n",
        "\n",
        "raw_data.create_dataset('images', shape=(100, 512, 512), chunks=(10, 128, 128), dtype='u2')\n",
        "raw_data.create_dataset('timestamps', shape=(100,), dtype='datetime64[ns]')\n",
        "\n",
        "processed.create_dataset('normalized', shape=(100, 512, 512), chunks=(10, 128, 128), dtype='f4')\n",
        "processed.create_dataset('features', shape=(100, 50), chunks=(20, 50), dtype='f4')\n",
        "\n",
        "root.attrs['experiment_id'] = 'EXP_2024_001'\n",
        "root.attrs['description'] = 'Advanced Zarr tutorial demonstration'\n",
        "root.attrs['created'] = str(np.datetime64('2024-01-01'))\n",
        "\n",
        "raw_data.attrs['instrument'] = 'Synthetic Camera'\n",
        "raw_data.attrs['resolution'] = [512, 512]\n",
        "processed.attrs['normalization'] = 'z-score'\n",
        "\n",
        "timestamps = np.datetime64('2024-01-01') + np.arange(100) * np.timedelta64(1, 'h')\n",
        "raw_data['timestamps'][:] = timestamps\n",
        "\n",
        "for i in range(100):\n",
        "    frame = np.random.poisson(100 + 50 * np.sin(2 * np.pi * i / 100), (512, 512)).astype('u2')\n",
        "    raw_data['images'][i] = frame\n",
        "\n",
        "print(f\"Created hierarchical structure with {len(list(root.group_keys()))} groups\")\n",
        "print(f\"Data arrays and groups created successfully\")\n",
        "\n",
        "print(\"\\n=== ADVANCED INDEXING ===\")\n",
        "\n",
        "volume_data = zarr.zeros((50, 20, 256, 256), chunks=(5, 5, 64, 64), dtype='f4',\n",
        "                        store=str(tutorial_dir / 'volume.zarr'), zarr_format=2)\n",
        "\n",
        "for t in range(50):\n",
        "    for z in range(20):\n",
        "        y, x = np.ogrid[:256, :256]\n",
        "        center_y, center_x = 128 + 20*np.sin(t*0.1), 128 + 20*np.cos(t*0.1)\n",
        "        focus_quality = 1 - abs(z - 10) / 10\n",
        "\n",
        "        signal = focus_quality * np.exp(-((y-center_y)**2 + (x-center_x)**2) / (50**2))\n",
        "        noise = 0.1 * np.random.random((256, 256))\n",
        "        volume_data[t, z] = (signal + noise).astype('f4')\n",
        "\n",
        "print(\"Various slicing operations:\")\n",
        "\n",
        "max_projection = np.max(volume_data[:, 10], axis=0)\n",
        "print(f\"Max projection shape: {max_projection.shape}\")\n",
        "\n",
        "z_stack = volume_data[25, :, 100:156, 100:156]\n",
        "print(f\"Z-stack subset: {z_stack.shape}\")\n",
        "\n",
        "bright_pixels = volume_data[volume_data > 0.5]\n",
        "print(f\"Pixels above threshold: {len(bright_pixels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE1TVqsrQpPA",
        "outputId": "0d8c1acb-7c0d-4458-f798-69cd8fff74a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== COMPRESSION AND CODECS ===\n",
            "Compression comparison:\n",
            "No compression: 3.82 MB (ratio: 1.000)\n",
            "LZ4: 1.64 MB (ratio: 0.430)\n",
            "ZSTD: 1.25 MB (ratio: 0.328)\n",
            "Sequential+ZSTD: 0.98 MB (ratio: 0.256)\n",
            "\n",
            "=== HIERARCHICAL DATA ORGANIZATION ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3126159196.py:45: ZarrDeprecationWarning: Use Group.create_array instead.\n",
            "  raw_data.create_dataset('images', shape=(100, 512, 512), chunks=(10, 128, 128), dtype='u2')\n",
            "/tmp/ipython-input-3126159196.py:46: ZarrDeprecationWarning: Use Group.create_array instead.\n",
            "  raw_data.create_dataset('timestamps', shape=(100,), dtype='datetime64[ns]')\n",
            "/tmp/ipython-input-3126159196.py:48: ZarrDeprecationWarning: Use Group.create_array instead.\n",
            "  processed.create_dataset('normalized', shape=(100, 512, 512), chunks=(10, 128, 128), dtype='f4')\n",
            "/tmp/ipython-input-3126159196.py:49: ZarrDeprecationWarning: Use Group.create_array instead.\n",
            "  processed.create_dataset('features', shape=(100, 50), chunks=(20, 50), dtype='f4')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created hierarchical structure with 3 groups\n",
            "Data arrays and groups created successfully\n",
            "\n",
            "=== ADVANCED INDEXING ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== PERFORMANCE OPTIMIZATION ===\")\n",
        "\n",
        "def process_chunk_serial(data, func):\n",
        "    results = []\n",
        "    for i in range(0, len(data), 100):\n",
        "        chunk = data[i:i+100]\n",
        "        results.append(func(chunk))\n",
        "    return np.concatenate(results)\n",
        "\n",
        "def gaussian_filter_1d(x, sigma=1.0):\n",
        "    kernel_size = int(4 * sigma)\n",
        "    if kernel_size % 2 == 0:\n",
        "        kernel_size += 1\n",
        "    kernel = np.exp(-0.5 * ((np.arange(kernel_size) - kernel_size//2) / sigma)**2)\n",
        "    kernel = kernel / kernel.sum()\n",
        "    return np.convolve(x.astype(float), kernel, mode='same')\n",
        "\n",
        "large_array = zarr.random.random((10000,), chunks=(1000,),\n",
        "                               store=str(tutorial_dir / 'large.zarr'), zarr_format=2)\n",
        "\n",
        "start_time = time.time()\n",
        "chunk_size = 1000\n",
        "filtered_data = []\n",
        "for i in range(0, len(large_array), chunk_size):\n",
        "    end_idx = min(i + chunk_size, len(large_array))\n",
        "    chunk_data = large_array[i:end_idx]\n",
        "    smoothed = np.convolve(chunk_data, np.ones(5)/5, mode='same')\n",
        "    filtered_data.append(smoothed)\n",
        "\n",
        "result = np.concatenate(filtered_data)\n",
        "processing_time = time.time() - start_time\n",
        "\n",
        "print(f\"Chunk-aware processing time: {processing_time:.4f}s\")\n",
        "print(f\"Processed {len(large_array):,} elements\")\n",
        "\n",
        "print(\"\\n=== VISUALIZATION ===\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('Advanced Zarr Tutorial - Data Visualization', fontsize=16)\n",
        "\n",
        "axes[0,0].plot(temporal_slice)\n",
        "axes[0,0].set_title('Temporal Evolution (Single Pixel)')\n",
        "axes[0,0].set_xlabel('Day of Year')\n",
        "axes[0,0].set_ylabel('Temperature')\n",
        "\n",
        "im1 = axes[0,1].imshow(spatial_slice, cmap='viridis')\n",
        "axes[0,1].set_title('Spatial Pattern (Day 100)')\n",
        "plt.colorbar(im1, ax=axes[0,1])\n",
        "\n",
        "methods = list(sizes.keys())\n",
        "ratios = [sizes[m]/original_size for m in methods]\n",
        "axes[0,2].bar(range(len(methods)), ratios)\n",
        "axes[0,2].set_xticks(range(len(methods)))\n",
        "axes[0,2].set_xticklabels(methods, rotation=45)\n",
        "axes[0,2].set_title('Compression Ratios')\n",
        "axes[0,2].set_ylabel('Size Ratio')\n",
        "\n",
        "axes[1,0].imshow(max_projection, cmap='hot')\n",
        "axes[1,0].set_title('Max Intensity Projection')\n",
        "\n",
        "z_profile = np.mean(volume_data[25, :, 120:136, 120:136], axis=(1,2))\n",
        "axes[1,1].plot(z_profile, 'o-')\n",
        "axes[1,1].set_title('Z-Profile (Center Region)')\n",
        "axes[1,1].set_xlabel('Z-slice')\n",
        "axes[1,1].set_ylabel('Mean Intensity')\n",
        "\n",
        "axes[1,2].plot(result[:1000])\n",
        "axes[1,2].set_title('Processed Signal (First 1000 points)')\n",
        "axes[1,2].set_xlabel('Sample')\n",
        "axes[1,2].set_ylabel('Amplitude')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NABT97sZQtOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eSINj0GMvoy"
      },
      "outputs": [],
      "source": [
        "print(\"\\n=== TUTORIAL SUMMARY ===\")\n",
        "print(\"Zarr features demonstrated:\")\n",
        "print(\"✓ Multi-dimensional array creation and manipulation\")\n",
        "print(\"✓ Optimal chunking strategies for different access patterns\")\n",
        "print(\"✓ Advanced compression with multiple codecs\")\n",
        "print(\"✓ Hierarchical data organization with metadata\")\n",
        "print(\"✓ Advanced indexing and data views\")\n",
        "print(\"✓ Performance optimization techniques\")\n",
        "print(\"✓ Integration with visualization tools\")\n",
        "\n",
        "def show_tree(path, prefix=\"\", max_depth=3, current_depth=0):\n",
        "    if current_depth > max_depth:\n",
        "        return\n",
        "    items = sorted(path.iterdir())\n",
        "    for i, item in enumerate(items):\n",
        "        is_last = i == len(items) - 1\n",
        "        current_prefix = \"└── \" if is_last else \"├── \"\n",
        "        print(f\"{prefix}{current_prefix}{item.name}\")\n",
        "        if item.is_dir() and current_depth < max_depth:\n",
        "            next_prefix = prefix + (\"    \" if is_last else \"│   \")\n",
        "            show_tree(item, next_prefix, max_depth, current_depth + 1)\n",
        "\n",
        "print(f\"\\nFiles created in {tutorial_dir}:\")\n",
        "show_tree(tutorial_dir)\n",
        "\n",
        "print(f\"\\nTotal disk usage: {sum(f.stat().st_size for f in tutorial_dir.rglob('*') if f.is_file()) / 1024**2:.2f} MB\")\n",
        "\n",
        "print(\"\\n🎉 Advanced Zarr tutorial completed successfully!\")"
      ]
    }
  ]
}